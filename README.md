# BizOps-Knowledge-Agent
BizOps Knowledge Agent: Implements a Gemini-powered RAG architecture (LlamaIndex + ChromaDB). It indexes internal HR, IT, &amp; Finance documents to securely deliver sourced, accurate answers to employee queries via a Streamlit UI, boosting efficiency.

1. Overview & Problem SolvedThis project successfully builds a fully functional BizOps Knowledge Base Agent. It solves the real-world operational problem of fragmented internal policy knowledge (HR, IT, Finance) that leads to delays and information errors.The agent enables employees to ask complex questions in natural language and receive an instant, accurate, and grounded answer based only on the organization's private documents, utilizing a robust Retrieval-Augmented Generation (RAG) architecture.
   
3. Technical ArchitectureThe agent follows the standard RAG pipeline, which is visualized in the Architecture Diagram included in this repository:Indexing Phase (ingest.py): Source documents (PDF/TXT) are loaded and split into optimized chunks, converted into vectors by the Google Embedding Model, and stored persistently in the ChromaDB Vector Store.Querying Phase (app.py): The user's query is vectorized, the most relevant chunks are retrieved from ChromaDB, and this context is sent to the Gemini 2.5 Flash LLM to generate a final, traceable answer.

4. Features & Limitations✅ Key FeaturesGrounded Answers: Uses RAG to prevent LLM hallucinations by forcing all responses to be synthesized only from provided internal document context.Low-Latency Generation: Utilizes the lightning-fast Gemini 2.5 Flash model and implements Streaming Output to drastically reduce perceived latency.Persistent Knowledge Base: The ChromaDB Vector Store allows for instant index loading via Streamlit's resource caching (@st.cache_resource).Cross-Document Synthesis: Successfully answers complex queries requiring synthesis from multiple policy documents (HR, IT, Finance).❌ LimitationsThe agent is currently limited to Question-Answering and does not execute external actions or transactions.The system does not yet utilize Metadata Filtering for faster retrieval across large numbers of categorized documents (see improvements below).4. Tech Stack & APIs Used (MANDATORY)ComponentTechnology / APIFunctionLLM & GenerationGemini 2.5 FlashHigh-speed, capable model for synthesizing context into human-readable answers.Embedding ModelGoogle GenAI EmbeddingConverts text to numerical vectors for semantic search.RAG FrameworkLlamaIndexOrchestrates the entire pipeline (chunking, indexing, retrieval, and streaming).Vector DBChromaDBStores the vectorized policy knowledge persistently (./chroma_db).UI/HostingStreamlitProvides the simple, functional, and deployable web interface.
  
5. Setup & Run Instructions (MANDATORY)These steps allow the project to be reproduced and run locally.PrerequisitesPython 3.9+Install Git (if not installed).A Gemini API Key (set as the GOOGLE_API_KEY environment variable).
